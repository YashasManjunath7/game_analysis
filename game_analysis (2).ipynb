{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dash --upgrade blinker --ignore-installed plotly pandas numpy scipy scikit-learn statsmodels seaborn matplotlib joblib pingouin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hmJL5fDoYQtm",
        "outputId": "017e7004-3252-45e9-c916-e7199870e219"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash\n",
            "  Downloading dash-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting statsmodels\n",
            "  Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pingouin\n",
            "  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting importlib-metadata (from dash)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting typing-extensions>=4.1.1 (from dash)\n",
            "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests (from dash)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting nest-asyncio (from dash)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting setuptools (from dash)\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly)\n",
            "  Downloading narwhals-1.33.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting packaging (from plotly)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting patsy>=0.5.6 (from statsmodels)\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pandas-flavor (from pingouin)\n",
            "  Downloading pandas_flavor-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tabulate (from pingouin)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting Jinja2>=3.1.2 (from Flask<3.1,>=1.0.4->dash)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting itsdangerous>=2.1.2 (from Flask<3.1,>=1.0.4->dash)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting click>=8.1.3 (from Flask<3.1,>=1.0.4->dash)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from Werkzeug<3.1->dash)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata->dash)\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting xarray (from pandas-flavor->pingouin)\n",
            "  Downloading xarray-2025.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->dash)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->dash)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->dash)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->dash)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading dash-3.0.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.33.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.8/322.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading xarray-2025.3.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, zipp, urllib3, tzdata, typing-extensions, threadpoolctl, tabulate, six, setuptools, pyparsing, pillow, packaging, numpy, nest-asyncio, narwhals, MarkupSafe, kiwisolver, joblib, itsdangerous, idna, fonttools, cycler, click, charset-normalizer, certifi, blinker, Werkzeug, scipy, retrying, requests, python-dateutil, plotly, patsy, Jinja2, importlib-metadata, contourpy, scikit-learn, pandas, matplotlib, Flask, xarray, statsmodels, seaborn, dash, pandas-flavor, pingouin\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-3.0.3 Jinja2-3.1.6 MarkupSafe-3.0.2 Werkzeug-3.0.6 blinker-1.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 contourpy-1.3.1 cycler-0.12.1 dash-3.0.2 fonttools-4.57.0 idna-3.10 importlib-metadata-8.6.1 itsdangerous-2.2.0 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.1 narwhals-1.33.0 nest-asyncio-1.6.0 numpy-2.2.4 packaging-24.2 pandas-2.2.3 pandas-flavor-0.6.0 patsy-1.0.1 pillow-11.1.0 pingouin-0.5.5 plotly-6.0.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.3 retrying-1.3.4 scikit-learn-1.6.1 scipy-1.15.2 seaborn-0.13.2 setuptools-78.1.0 six-1.17.0 statsmodels-0.14.4 tabulate-0.9.0 threadpoolctl-3.6.0 typing-extensions-4.13.1 tzdata-2025.2 urllib3-2.3.0 xarray-2025.3.1 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "importlib_metadata",
                  "kiwisolver",
                  "pkg_resources",
                  "six",
                  "zipp"
                ]
              },
              "id": "d40b303424a64d69aa765479435c5f5a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "0OaHX_ciYC5g",
        "outputId": "0a82a644-d41f-48c5-bffa-7215dc0047b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cleaned, shape: (50751, 15)\n",
            "Sample data:    year  price_final  discount  win  mac  linux\n",
            "0  2008     0.117803 -0.300677    1    0      0\n",
            "1  2011    -0.489831 -0.300677    1    0      0\n",
            "2  2013     0.551827 -0.300677    1    1      1\n",
            "3  2014     0.551827 -0.300677    1    0      0\n",
            "4  2014     0.291412 -0.300677    1    1      0\n",
            "Recommendation matrix built with shape: (50751, 50751)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import dash\n",
        "from dash import dcc, html, Input, Output, Dash\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "import pingouin as pg\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from typing import Tuple, Union, List\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "def load_and_clean_data(file_path=\"games.csv\"):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df['date_release'] = pd.to_datetime(df['date_release'], errors='coerce')\n",
        "        required_cols = ['title', 'rating', 'positive_ratio']\n",
        "        if not all(col in df.columns for col in required_cols):\n",
        "            raise ValueError(\"Dataset missing required columns.\")\n",
        "        df = df.dropna(subset=required_cols).drop_duplicates(subset=['title'])\n",
        "        df['year'] = df['date_release'].dt.year\n",
        "\n",
        "        # Ensure numeric and boolean types for recommendation matrix columns\n",
        "        le_rating = LabelEncoder()\n",
        "        df['rating_encoded'] = le_rating.fit_transform(df['rating'].astype(str))\n",
        "        df['price_final'] = pd.to_numeric(df.get('price_final', 0), errors='coerce').fillna(0)\n",
        "        df['positive_ratio'] = pd.to_numeric(df['positive_ratio'], errors='coerce').fillna(0)\n",
        "        df['win'] = df.get('win', False).astype(int)  # Convert bool/strings to 0/1\n",
        "        df['mac'] = df.get('mac', False).astype(int)\n",
        "        df['linux'] = df.get('linux', False).astype(int)\n",
        "        df['user_reviews'] = pd.to_numeric(df.get('user_reviews', 0), errors='coerce').fillna(0)\n",
        "        df['steam_deck'] = df.get('steam_deck', False).astype(int)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        numerical_cols = ['price_final', 'discount', 'positive_ratio']\n",
        "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols].fillna(0).astype(float))\n",
        "        print(f\"Data cleaned, shape: {df.shape}\")\n",
        "        print(f\"Sample data: {df[['year', 'price_final', 'discount', 'win', 'mac', 'linux']].head()}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data cleaning: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- Rating Analysis ---\n",
        "def analyze_ratings(df, selected_title=None):\n",
        "    if not all(col in df.columns for col in ['rating', 'positive_ratio']):\n",
        "        return None, None, None\n",
        "    try:\n",
        "        rating_counts = df['rating'].value_counts().reset_index()\n",
        "        rating_counts.columns = ['rating', 'count']\n",
        "        avg_positive_by_rating = df.groupby('rating')['positive_ratio'].mean()\n",
        "        stats_summary = df.groupby('rating')['positive_ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
        "        stats_summary = stats_summary[stats_summary['count'] > 0].copy()\n",
        "        stats_summary['std'] = stats_summary['std'].fillna(0)\n",
        "        confidence_level = 0.95\n",
        "        stats_summary['ci_lower'] = stats_summary.apply(\n",
        "            lambda row: ttest_ind(df[df['rating'] == row['rating']]['positive_ratio'],\n",
        "                                  df[df['rating'] != row['rating']]['positive_ratio'],\n",
        "                                  equal_var=False)[1] if row['count'] > 1 else row['mean'], axis=1)\n",
        "        stats_summary['ci_upper'] = stats_summary['mean']\n",
        "\n",
        "        if selected_title and selected_title in df['title'].values:\n",
        "            selected_rating = df[df['title'] == selected_title]['rating'].iloc[0]\n",
        "            rating_counts['selected'] = rating_counts['rating'].apply(lambda x: 'Selected' if x == selected_rating else 'Others')\n",
        "        else:\n",
        "            rating_counts['selected'] = 'Others'\n",
        "\n",
        "        return rating_counts, avg_positive_by_rating, stats_summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error in rating analysis: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Price/Discount Trends ---\n",
        "def price_trends(df, selected_title=None, input_price=None, input_discount=None):\n",
        "    required_cols = ['year', 'price_final', 'discount', 'date_release']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"Missing columns for price trends: {set(required_cols) - set(df.columns)}\")\n",
        "        return pd.DataFrame({'year': [0], 'price_final': [0.0], 'discount': [0.0]})\n",
        "    try:\n",
        "        df['price_final'] = pd.to_numeric(df['price_final'], errors='coerce').fillna(0)\n",
        "        df['discount'] = pd.to_numeric(df['discount'], errors='coerce').fillna(0)\n",
        "        df['year'] = pd.to_numeric(df['year'], errors='coerce').fillna(df['year'].min() if not df['year'].isna().all() else 0)\n",
        "\n",
        "        yearly_avg = df.groupby('year')[['price_final', 'discount']].mean().reset_index()\n",
        "        correlation = df['price_final'].corr(df['discount'])\n",
        "        print(f\"Correlation between price and discount: {correlation:.4f}\")\n",
        "\n",
        "        if pd.api.types.is_datetime64_any_dtype(df['date_release']):\n",
        "            ts = df.dropna(subset=['date_release', 'price_final']).set_index('date_release')['price_final'].resample('YE').mean().dropna()\n",
        "            if len(ts) > 1:\n",
        "                decomposition = seasonal_decompose(ts, model='additive', period=1)\n",
        "                trend = decomposition.trend\n",
        "                yearly_avg['year'] = pd.to_datetime(yearly_avg['year'].astype(int), format='%Y')\n",
        "                yearly_avg['trend'] = trend.reindex(yearly_avg['year'], method='ffill').fillna(method='bfill')\n",
        "                yearly_avg['year'] = yearly_avg['year'].dt.year\n",
        "            else:\n",
        "                yearly_avg['trend'] = yearly_avg['price_final']\n",
        "        else:\n",
        "            yearly_avg['trend'] = yearly_avg['price_final']\n",
        "\n",
        "        if selected_title and selected_title in df['title'].values:\n",
        "            selected_game = df[df['title'] == selected_title][['year', 'price_final', 'discount']].iloc[0]\n",
        "            if input_price is not None and input_discount is not None:\n",
        "                yearly_avg.loc[yearly_avg['year'] == selected_game['year'], 'price_final'] = input_price\n",
        "                yearly_avg.loc[yearly_avg['year'] == selected_game['year'], 'discount'] = input_discount\n",
        "            else:\n",
        "                yearly_avg.loc[yearly_avg['year'] == selected_game['year'], 'price_final'] = selected_game['price_final']\n",
        "                yearly_avg.loc[yearly_avg['year'] == selected_game['year'], 'discount'] = selected_game['discount']\n",
        "\n",
        "        yearly_avg = yearly_avg.fillna(0)\n",
        "        print(f\"Price trends DataFrame: {yearly_avg}\")\n",
        "        return yearly_avg\n",
        "    except Exception as e:\n",
        "        print(f\"Error in price trend analysis: {str(e)}\")\n",
        "        return pd.DataFrame({'year': [0], 'price_final': [0.0], 'discount': [0.0]})\n",
        "\n",
        "# --- Recommendation System (Fixed) ---\n",
        "def build_recommendation_matrix(df, method='cosine'):\n",
        "    required_cols = ['rating_encoded', 'positive_ratio', 'price_final', 'win', 'mac', 'linux']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"Missing columns for recommendation matrix: {set(required_cols) - set(df.columns)}\")\n",
        "        return None\n",
        "    try:\n",
        "        # Ensure all columns are numeric\n",
        "        feature_matrix = df[required_cols].copy()\n",
        "        for col in feature_matrix.columns:\n",
        "            feature_matrix[col] = pd.to_numeric(feature_matrix[col], errors='coerce').fillna(0)\n",
        "        sparse_matrix = csr_matrix(feature_matrix.values.astype(float))  # Explicitly cast to float\n",
        "        similarity_matrix = cosine_similarity(sparse_matrix, dense_output=False)\n",
        "        print(f\"Recommendation matrix built with shape: {similarity_matrix.shape}\")\n",
        "        return similarity_matrix\n",
        "    except Exception as e:\n",
        "        print(f\"Error building recommendation matrix: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def recommend_games(title, df, similarity_matrix, n_recommendations=5):\n",
        "    if title not in df['title'].values:\n",
        "        return [\"Game not found\"]\n",
        "    try:\n",
        "        idx = df[df['title'] == title].index[0]\n",
        "        sim_scores = similarity_matrix[idx].toarray().flatten()\n",
        "        sim_scores = list(enumerate(sim_scores))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n_recommendations+1]\n",
        "        game_indices = [i[0] for i in sim_scores]\n",
        "        return df['title'].iloc[game_indices].drop_duplicates().tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in recommendations: {str(e)}\")\n",
        "        return [\"Error in recommendation\"]\n",
        "\n",
        "# --- Success Prediction ---\n",
        "def train_success_model(df):\n",
        "    required_cols = ['price_final', 'discount', 'user_reviews', 'win', 'mac', 'linux', 'steam_deck', 'positive_ratio']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return None, None, None\n",
        "    try:\n",
        "        X = df[required_cols[:-1]]\n",
        "        y = df['positive_ratio']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X.fillna(0), y, test_size=0.2, random_state=42)\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        r2_score = model.score(X_test, y_test)\n",
        "        return model, r2_score, 0\n",
        "    except Exception as e:\n",
        "        print(f\"Error in success prediction: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Steam Deck Impact ---\n",
        "def steam_deck_impact(df):\n",
        "    if 'steam_deck' not in df.columns or 'positive_ratio' not in df.columns:\n",
        "        return None, None, None, None\n",
        "    try:\n",
        "        deck_games = df[df['steam_deck'] == True]['positive_ratio'].dropna()\n",
        "        no_deck_games = df[df['steam_deck'] == False]['positive_ratio'].dropna()\n",
        "        if len(deck_games) < 2 or len(no_deck_games) < 2:\n",
        "            return None, None, None, None\n",
        "        t_stat, p_val = ttest_ind(deck_games, no_deck_games, equal_var=False)\n",
        "        effect_size = pg.compute_effsize(deck_games, no_deck_games, eftype='cohen')\n",
        "        return t_stat, p_val, effect_size, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Steam Deck impact analysis: {str(e)}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# --- Tag Prediction ---\n",
        "def train_tag_model(df, text_column='title'):\n",
        "    if text_column not in df.columns or 'rating' not in df.columns:\n",
        "        return None, None, None\n",
        "    try:\n",
        "        tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "        X = tfidf.fit_transform(df[text_column].fillna('').astype(str))\n",
        "        y = df['rating']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        return model, tfidf, accuracy\n",
        "    except Exception as e:\n",
        "        print(f\"Error in tag prediction: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Dynamic Pricing ---\n",
        "def train_pricing_model(df):\n",
        "    required_cols = ['positive_ratio', 'user_reviews', 'win', 'mac', 'linux', 'steam_deck', 'price_final']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return None, None, None\n",
        "    try:\n",
        "        X = df[required_cols[:-1]]\n",
        "        y = df['price_final']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X.fillna(0), y, test_size=0.2, random_state=42)\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        r2_score = model.score(X_test, y_test)\n",
        "        return model, r2_score, 0\n",
        "    except Exception as e:\n",
        "        print(f\"Error in pricing model: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Load Data and Models ---\n",
        "df = load_and_clean_data(\"games.csv\")\n",
        "if df.empty:\n",
        "    print(\"Failed to load data. Using empty DataFrame.\")\n",
        "cosine_sim = build_recommendation_matrix(df) if not df.empty else None\n",
        "success_model, _, _ = train_success_model(df) if not df.empty else (None, None, None)\n",
        "pricing_model, _, _ = train_pricing_model(df) if not df.empty else (None, None, None)\n",
        "tag_model, tfidf, _ = train_tag_model(df) if not df.empty else (None, None, None)\n",
        "\n",
        "# Save models if not already saved (optional)\n",
        "if cosine_sim is not None:\n",
        "    joblib.dump(cosine_sim, 'recommendation_matrix.joblib')\n",
        "if success_model is not None:\n",
        "    joblib.dump(success_model, 'success_model.joblib')\n",
        "if pricing_model is not None:\n",
        "    joblib.dump(pricing_model, 'pricing_model.joblib')\n",
        "if tag_model is not None and tfidf is not None:\n",
        "    joblib.dump(tag_model, 'tag_model.joblib')\n",
        "    joblib.dump(tfidf, 'tfidf.joblib')\n",
        "\n",
        "# Initialize Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "# Layout\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Steam Game Analytics and Recommendation Platform\"),\n",
        "    html.P(\"Analyze, predict, and recommend Steam games!\"),\n",
        "\n",
        "    html.Label(\"Game Title:\"),\n",
        "    dcc.Input(id=\"title-input\", type=\"text\", placeholder=\"e.g., Dungeon of the ENDLESS™\", value=\"\"),\n",
        "\n",
        "    html.Label(\"Price ($):\"),\n",
        "    dcc.Slider(id=\"price-input\", min=0, max=100, step=1, value=10, marks={i: str(i) for i in range(0, 101, 20)}),\n",
        "\n",
        "    html.Label(\"Discount (%):\"),\n",
        "    dcc.Slider(id=\"discount-input\", min=0, max=100, step=1, value=0, marks={i: str(i) for i in range(0, 101, 20)}),\n",
        "\n",
        "    dcc.Graph(id=\"rating-distribution\"),\n",
        "    dcc.Graph(id=\"price-trends\"),\n",
        "    html.Div(id=\"recommendations-output\"),\n",
        "    html.Div(id=\"success-prediction-output\"),\n",
        "    html.Div(id=\"steam-deck-impact-output\"),\n",
        "    html.Div(id=\"tag-prediction-output\"),\n",
        "    html.Div(id=\"pricing-suggestion-output\")\n",
        "])\n",
        "\n",
        "# Callback to update dashboard\n",
        "@app.callback(\n",
        "    [Output(\"rating-distribution\", \"figure\"),\n",
        "     Output(\"price-trends\", \"figure\"),\n",
        "     Output(\"recommendations-output\", \"children\"),\n",
        "     Output(\"success-prediction-output\", \"children\"),\n",
        "     Output(\"steam-deck-impact-output\", \"children\"),\n",
        "     Output(\"tag-prediction-output\", \"children\"),\n",
        "     Output(\"pricing-suggestion-output\", \"children\")],\n",
        "    [Input(\"title-input\", \"value\"),\n",
        "     Input(\"price-input\", \"value\"),\n",
        "     Input(\"discount-input\", \"value\")]\n",
        ")\n",
        "def update_dashboard(title_input: str, price_input: float, discount_input: float) -> Tuple:\n",
        "    print(f\"Callback triggered with: Title={title_input}, Price={price_input}, Discount={discount_input}\")\n",
        "\n",
        "    # Default outputs in case of errors\n",
        "    default_fig = px.bar(title=\"Error: Unable to Process\")\n",
        "    default_text = \"Error: Unable to Process\"\n",
        "\n",
        "    # Input validation\n",
        "    if not title_input or (not df.empty and title_input not in df['title'].values):\n",
        "        error_msg = f\"Error: Game '{title_input}' not found or invalid input\"\n",
        "        print(f\"Returning error: {error_msg}\")\n",
        "        return (default_fig, default_fig, error_msg, error_msg, error_msg, error_msg, error_msg)\n",
        "\n",
        "    try:\n",
        "        # Rating Analysis\n",
        "        rating_counts, _, _ = analyze_ratings(df, title_input)\n",
        "        if rating_counts is None:\n",
        "            print(\"Rating analysis returned None\")\n",
        "            rating_fig = default_fig\n",
        "        else:\n",
        "            rating_fig = px.bar(rating_counts, x=\"rating\", y=\"count\", color=\"selected\",\n",
        "                                title=\"Rating Distribution (Selected Game Highlighted)\",\n",
        "                                color_discrete_map={'Selected': 'red', 'Others': 'blue'})\n",
        "\n",
        "        # Price Trends\n",
        "        trends = price_trends(df, title_input, price_input, discount_input)\n",
        "        if trends is None or trends.empty:\n",
        "            print(\"Price trends returned None or empty\")\n",
        "            trends_fig = default_fig\n",
        "        else:\n",
        "            trends_fig = px.line(trends, x=\"year\", y=[\"price_final\", \"discount\"],\n",
        "                                 title=f\"Price/Discount Trends (Adjusted for {title_input})\")\n",
        "            trends_fig.update_layout(yaxis_range=[trends[['price_final', 'discount']].min().min() - 1,\n",
        "                                                  trends[['price_final', 'discount']].max().max() + 1])\n",
        "\n",
        "        # Recommendations\n",
        "        if cosine_sim is None or df.empty:\n",
        "            recs_output = \"Recommendation matrix unavailable\"\n",
        "        else:\n",
        "            recs = recommend_games(title_input, df, cosine_sim)\n",
        "            if recs is None or \"Error\" in recs[0]:\n",
        "                print(\"Recommendations failed\")\n",
        "                recs_output = \"No recommendations available\"\n",
        "            else:\n",
        "                recs_output = html.Ul([html.Li(game) for game in recs])\n",
        "\n",
        "        # Success Prediction\n",
        "        if success_model is None or df.empty:\n",
        "            success_output = \"Success prediction unavailable\"\n",
        "        else:\n",
        "            game_data = df[df['title'] == title_input][['price_final', 'discount', 'user_reviews', 'win', 'mac', 'linux', 'steam_deck']].iloc[0]\n",
        "            game_data_df = pd.DataFrame([game_data], columns=['price_final', 'discount', 'user_reviews', 'win', 'mac', 'linux', 'steam_deck'])\n",
        "            success_pred = success_model.predict(game_data_df)[0]\n",
        "            success_output = f\"Predicted Positive Ratio: {success_pred:.2f}%\"\n",
        "\n",
        "        # Steam Deck Impact\n",
        "        t_stat, p_val, effect_size, _ = steam_deck_impact(df)\n",
        "        if p_val is None:\n",
        "            print(\"Steam Deck impact returned None\")\n",
        "            deck_impact = \"Steam Deck impact analysis failed\"\n",
        "        else:\n",
        "            deck_impact = f\"Steam Deck Impact - p-value: {p_val:.4f}, Effect Size: {effect_size:.4f}\"\n",
        "\n",
        "        # Tag Prediction\n",
        "        if tfidf is None or tag_model is None or df.empty:\n",
        "            tag_output = \"No tag prediction available\"\n",
        "        else:\n",
        "            title_vec = tfidf.transform([title_input]).toarray()\n",
        "            tag_pred = tag_model.predict(title_vec)[0]\n",
        "            tag_output = f\"Inferred Rating/Tag: {tag_pred}\"\n",
        "\n",
        "        # Dynamic Pricing\n",
        "        if pricing_model is None or df.empty:\n",
        "            pricing_output = f\"Suggested Price: ${price_input:.2f} (default)\"\n",
        "        else:\n",
        "            pricing_input = [success_pred if success_pred is not None else 0, df['user_reviews'].mean() if not df.empty else 0, 1, 0, 0, 1]\n",
        "            pricing_input_df = pd.DataFrame([pricing_input], columns=['positive_ratio', 'user_reviews', 'win', 'mac', 'linux', 'steam_deck'])\n",
        "            price_suggestion = pricing_model.predict(pricing_input_df)[0]\n",
        "            pricing_output = f\"Suggested Price: ${price_suggestion:.2f}\"\n",
        "\n",
        "        print(\"Callback returning successful outputs\")\n",
        "        return (rating_fig, trends_fig, recs_output, success_output, deck_impact, tag_output, pricing_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error in callback: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return (default_fig, default_fig, error_msg, error_msg, error_msg, error_msg, error_msg)\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ]
    }
  ]
}